{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17066957-f82c-44d5-b1d8-3f63c6fa9f10",
   "metadata": {},
   "source": [
    "### 1.走流程图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9757a-93a3-47bf-aa66-60852fc4596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_candidates(row,data_base,new_in):\n",
    "    test_index = row.name\n",
    "    \n",
    "    # 创建训练集副本\n",
    "    candidates = data_base.copy(deep = False)\n",
    "    candidates[\"type\"] = 0\n",
    "    candidates[\"info\"] = 0\n",
    "    candidates[\"plant\"] = 0\n",
    "    candidates[\"number\"] = 0\n",
    "    candidates[\"state\"] = 0\n",
    "    candidates[\"ord\"] = 0\n",
    "    candidates[\"fg&rp\"] = 0\n",
    "    candidates[\"newin\"] = 0\n",
    "    candidates[\"pos\"] = 0\n",
    "\n",
    "\n",
    "    # 1. type比对\n",
    "    type = row[\"TYPE\"]\n",
    "    info = row[\"INFO\"]\n",
    "    # type相等\n",
    "    myindex_1 = candidates.index[\n",
    "        candidates[\"TYPE\"].isin(\n",
    "            list(df_cos_sim.columns[abs(df_cos_sim.loc[type, :] - 1) <= 0.000001])\n",
    "        )\n",
    "    ]\n",
    "    myindex_1_1 = myindex_1[candidates.loc[myindex_1, \"INFO\"] == info]\n",
    "    # myindex_1_2 = myindex_1[candidates.loc[myindex_1, \"INFO\"] != info]\n",
    "    candidates.loc[myindex_1, \"type\"] += 1\n",
    "    candidates.loc[myindex_1_1, \"info\"] += 1\n",
    "\n",
    "    # type不相等\n",
    "    myindex_2 = candidates.index[\n",
    "        candidates[\"TYPE\"].isin(\n",
    "            list(df_cos_sim.columns[abs(df_cos_sim.loc[type, :] - 1) > 0.000001])\n",
    "        )\n",
    "    ]\n",
    "    candidates.loc[myindex_2, \"type\"] = df_cos_sim.loc[\n",
    "        type, candidates.loc[myindex_2, \"TYPE\"]\n",
    "    ].values\n",
    "\n",
    "    # fg&pos比对\n",
    "    fgrp = row[\"FGRP\"]\n",
    "    pos = row[\"POS\"]\n",
    "    '''\n",
    "    candidates.loc[\n",
    "        (candidates[\"FGRP\"] == fgrp) & (candidates[\"POS\"] == pos), \"fg&rp\"\n",
    "    ] += 1\n",
    "    '''\n",
    "    candidates.loc[\n",
    "   (candidates[\"POS\"] == pos), \"pos\"\n",
    "    ] += 1 \n",
    "    \n",
    "    candidates.loc[\n",
    "   (candidates[\"FGRP\"] == fgrp), \"fg&rp\"\n",
    "    ] += 1 \n",
    "\n",
    "    # number\n",
    "    num = row['NUMBER']\n",
    "    candidates.loc[\n",
    "        (candidates[\"NUMBER\"] == num), \"number\"\n",
    "    ] += 1\n",
    "\n",
    "\n",
    "    # newin比对\n",
    "    newin = new_in\n",
    "    myindex_4 = candidates.index\n",
    "\n",
    "    myindex_4_1 = candidates.loc[myindex_4].index[\n",
    "        candidates.loc[myindex_4, \"NEWIN\"].isin(newin)\n",
    "    ]\n",
    "    candidates.loc[myindex_4_1, \"newin\"] += 1\n",
    "\n",
    "    # PLANT\n",
    "    plant = row[\"PLANT\"]\n",
    "    candidates.loc[candidates[\"PLANT\"] == plant, \"plant\"] += 1\n",
    "\n",
    "    plant_list = [\n",
    "        \"CHN03\",\n",
    "        \"DAQ03\",\n",
    "        \"LUQ03\",\n",
    "        \"CHA03\",\n",
    "        \"BP2TC\",\n",
    "        \"BP2TH\",\n",
    "        \"BS8CA\",\n",
    "        \"BSNRA\",\n",
    "    ]\n",
    "\n",
    "    candidates.loc[\n",
    "        (candidates[\"PLANT\"].isin(plant_list)) & (candidates[\"PLANT\"] != plant), \"plant\"\n",
    "    ] += 0.8\n",
    "\n",
    "    # state比对\n",
    "    states = [\"P\", \"I\"]\n",
    "    candidates.loc[candidates[\"S\"].isin(states), \"state\"] += 1\n",
    "\n",
    "    # ord比对\n",
    "    candidates.loc[candidates[\"ORD\"] == \"MO\", \"ord\"] += 1\n",
    "\n",
    "    #PSS比对\n",
    "\n",
    "\n",
    "    # 计算最终得分\n",
    "    candidates[\"final_score\"] = (\n",
    "        0.55 * candidates[\"type\"]\n",
    "        + 0.15 * candidates[\"info\"]\n",
    "        + 0.08 * candidates[\"fg&rp\"]\n",
    "        +0.04*candidates[\"pos\"]\n",
    "        + 0.18 * candidates[\"number\"]\n",
    "    ) * 0.8 + (\n",
    "        0.47 * candidates[\"newin\"]\n",
    "        + 0.47 * candidates[\"plant\"]\n",
    "        + 0.03 * candidates[\"ord\"]\n",
    "        + 0.03 * candidates[\"state\"]\n",
    "    ) * 0.2\n",
    "    final = candidates.sort_values(by=\"final_score\", ascending=False)\n",
    "    final_output = final.iloc[:3, :]\n",
    "    \n",
    "    print(row.name)\n",
    "\n",
    "    return final_output.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d431d4-b44a-4d9b-9215-dbe7c890f21e",
   "metadata": {},
   "source": [
    "### 2.data_base预处理\n",
    "1.删除剔除UL=0，UL或者LC或者长宽高为空/1的数据\n",
    "\n",
    "2.剔除状态错误数据（EXP=Y/S=N）\n",
    "\n",
    "3.将NAME分解为TYPE-INFO，若有多个-，按照第一个-进行分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d14ffa-9150-4098-be7e-63f265291b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_base_preprocess(data_base,test_newin=\"\"):\n",
    "    \n",
    "    '''\n",
    "    1. data_base:读取的VSIM表格\n",
    "    2.test_newin默认空，检测数据的项目号，需要在data_base中删除\n",
    "    '''\n",
    "    \n",
    "    #提取所需要的列\n",
    "    data_base = data_base[[\"NUMBER\",\"NEWIN\",\"NAME\",\"PSS\",\"PLANT\",\"DRAWING NO\",\"EXP\",\"ORD\",\"REQ\",\"S\",\"STATE\",\"LC\",\"UL\",\"LENGTH(MM)\",\"WIDTH(MM)\",\"HEIGHT(MM)\",\"EMB1\",\"FGRP\",\"POS\"]]\n",
    "    #删掉test检测数据\n",
    "    data_base = data_base[data_base[\"NEWIN\"] !=test_newin]\n",
    "    \n",
    "    # 通过NAME拆分INFO TYPE\n",
    "    data_base[\"NAMELIST\"] = data_base[\"NAME\"].str.rsplit(\"-\", n=0)\n",
    "    \n",
    "    data_base[\"TYPE\"] = data_base[\"NAMELIST\"].str[0].str.rsplit(\",\").str[0]\n",
    "    data_base[\"INFO\"] = data_base[\"NAMELIST\"].str[1]\n",
    "    \n",
    "    #剔除UL=0，UL或者LC或者长宽高为空的数据\n",
    "    data_base = data_base.loc[-( (data_base[\"UL\"] == 0) | (data_base[\"UL\"].isna())| (data_base[\"LENGTH(MM)\"].isna() | data_base[\"LC\"].isna()) | (data_base[\"LENGTH(MM)\"]*data_base[\"WIDTH(MM)\"]*data_base[\"HEIGHT(MM)\"]==1) | (data_base[\"LENGTH(MM)\"]*data_base[\"WIDTH(MM)\"]*data_base[\"HEIGHT(MM)\"]==0))]\n",
    "    data_base = data_base.loc[-((data_base[\"EXP\"] == \"Y\") | (data_base[\"S\"] == \"N\"))]\n",
    "    \n",
    "    return data_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b7d02-3a9c-432d-b1b0-d9bd20f26838",
   "metadata": {},
   "source": [
    "### 3.test预处理\n",
    "将NAME分解为TYPE-INFO，若有多个-，按照第一个-进行分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42245db-a894-450b-ac77-0b416a6c7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocess(axa,single_bom,plant):\n",
    "        \n",
    "        test1 = axa[[\"PART NO\",\"PART NAME\",\"PART DESCRIPTION\"]]\n",
    "        test2 = single_bom[[\"Fgrp\",\"Pos \",\"PSS\",\"-Partno-\",\"Description-------\"]]\n",
    "        test1[[\"PART NAME\",\"PART DESCRIPTION\"]] = test1[[\"PART NAME\",\"PART DESCRIPTION\"]].apply(lambda x : x.apply(lambda y:str(y).strip()))\n",
    "        test2[\"Description-------\"] = test2[\"Description-------\"].apply(lambda y:str(y).strip())\n",
    "        test = pd.merge(test1,test2,how = \"right\",left_on = \"PART NO\",right_on = \"-Partno-\")\n",
    "        \n",
    "        test[\"NAME\"] = test[\"PART NAME\"]+\"-\"+test[\"PART DESCRIPTION\"]\n",
    "        test[\"NAME\"] = test[\"NAME\"].apply(lambda x : str(x).replace(\">\",\"\"))\n",
    "        \n",
    "        test[\"NAMELIST\"] = test[\"NAME\"].str.rsplit(\"-\", n=0)\n",
    "        \n",
    "        test[\"TYPE\"] = test[\"NAMELIST\"].str[0].str.rsplit(\",\").str[0]\n",
    "        test[\"INFO\"] = test[\"NAMELIST\"].str[1]\n",
    "        \n",
    "        test.rename(columns = {\"Fgrp\":\"FGRP\",\"Pos \":\"POS\",\"PART NO\":\"NUMBER\"},inplace = True)\n",
    "        \n",
    "        test.dropna(subset = [\"NAME\",\"FGRP\",\"POS\",\"NUMBER\"],inplace = True)\n",
    "        \n",
    "        test[\"PLANT\"] = plant\n",
    "        \n",
    "        return test[[\"NUMBER\",\"NAME\",\"PLANT\",\"TYPE\",\"INFO\",\"FGRP\",\"POS\",\"PSS\"]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68270d9d-ce73-4f60-aea0-ab52d6778094",
   "metadata": {},
   "source": [
    "### 3.删除TYPE中的干扰项（包括一些形容词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdeddc5b-4f8d-4e80-8f23-426796ee982b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TYPE_process(data_base,mylist):\n",
    "\n",
    "    tt = data_base[\"TYPE\"].apply(lambda x: x.replace(\",\", \" \"))\n",
    "    for word in mylist:\n",
    "        tt = tt.apply(lambda x: x.replace(word, \"\"))\n",
    "    data_base[\"TYPE\"] = tt.apply(lambda x: x.strip())\n",
    "    \n",
    "    return data_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04154711-3a3b-465b-8464-5f36e329552b",
   "metadata": {},
   "source": [
    "### 4.计算TYPE和TYPE之间的相似度\n",
    "采用w2v和余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44279be3-1c60-4942-bfd8-2e3c62247d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_similarity(data_base,test):\n",
    "    \n",
    "    df = pd.concat([test,data_base])\n",
    "    document = df.loc[:, \"TYPE\"].drop_duplicates().to_list()\n",
    "    \n",
    "    name = [x.strip() for x in document]\n",
    "    document = [x.strip().split(\" \") for x in document]\n",
    "    \n",
    "    model = gensim.models.Word2Vec(sentences=document, min_count=1)\n",
    "    word2v = []\n",
    "    for i in document:\n",
    "        try:\n",
    "            vec_king = model.wv[i].mean(axis=0)\n",
    "            word2v.append(list(vec_king))\n",
    "        except:\n",
    "            print(i)\n",
    "    \n",
    "    cos_sim = cosine_similarity(np.array(word2v))\n",
    "    df_cos_sim = pd.DataFrame(cos_sim, index=name, columns=name)\n",
    "    df_cos_sim = (df_cos_sim+1)/2\n",
    "    \n",
    "    return df_cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa253d-6de3-497c-966f-4e26015ad75f",
   "metadata": {},
   "source": [
    "### 5.得到output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c186142c-42cf-4651-97c2-e42e88f405a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_output(each_test_candidates):\n",
    "    \n",
    "    #to_output\n",
    "    mydf = pd.DataFrame()\n",
    "    myindex = each_test_candidates.index\n",
    "    k = 0\n",
    "    for i in each_test_candidates:\n",
    "        i[\"index\"] = myindex[k]\n",
    "        i[\"candidates\"] = i.index\n",
    "        mydf = pd.concat([mydf, i])\n",
    "        k = k + 1\n",
    "    arrays = [np.array(mydf[\"index\"]), np.array(mydf[\"candidates\"])]\n",
    "    mm = pd.DataFrame(\n",
    "        mydf.drop(columns=[\"index\", \"candidates\"]).values,\n",
    "        index=arrays,\n",
    "        columns=mydf.drop(columns=[\"index\", \"candidates\"]).columns,\n",
    "    ).reset_index()\n",
    "    \n",
    "    return mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79422d3-9a11-4014-8c14-0bf5bb09aee1",
   "metadata": {},
   "source": [
    "### 6.如果test从data_base里面取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5008953b-a59c-4c2f-bd4a-493deab5d425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_from_database(data_base,size=0.02):\n",
    "    \n",
    "    train,test = train_test_split(data_base,test_size = size)\n",
    "    \n",
    "    return train,test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d43f3f8-ed8b-4a3e-837d-5484d9bd522d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#读取VSIM表格\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     data_base \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mzli242\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVOLVO\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m0815\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata base.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     axa \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mzli242\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVOLVO\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpackaging final_version\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAXA P519.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m,header \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m )\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m4\u001b[39m:,:]\n\u001b[1;32m      8\u001b[0m     single_bom \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mzli242\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVOLVO\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpackaging final_version\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSingle bom.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m,header \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m3\u001b[39m:,:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #读取VSIM表格\n",
    "    data_base = pd.read_excel(r\"C:\\Users\\zli242\\Desktop\\VOLVO\\0815\\data base.xlsx\")\n",
    "    axa = pd.read_excel(r\"C:\\Users\\zli242\\Desktop\\VOLVO\\packaging final_version\\AXA P519.xlsx\",header =4 ).iloc[4:,:]\n",
    "    single_bom = pd.read_excel(r\"C:\\Users\\zli242\\Desktop\\VOLVO\\packaging final_version\\Single bom.xlsx\",header = 3).iloc[3:,:]\n",
    "    plant = \"CHN03\"\n",
    "    #清洗表格，删除样本数据的项目号\n",
    "    data_base_processed = data_base_preprocess(data_base,test_newin = \"\")\n",
    "    #清洗test\n",
    "    test_processed = test_preprocess(axa, single_bom, plant)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    从data_base中提取test\n",
    "    train,mytest = test_from_database(data_base_processed,size=0.02)\n",
    "    '''\n",
    "    \n",
    "    # 删除样本数据和database的干扰项\n",
    "    mylist = [\n",
    "        \"UNCOLORED\",\n",
    "        \"KSOCOLOR\",\n",
    "        \"CKDCOLOR\",\n",
    "        \"CHARCOAL\",\n",
    "        \"OFFBLACK\",\n",
    "        \"CHARCOAL SOLID\",\n",
    "        \"DAWN\",\n",
    "        \"BRIGHT\",\n",
    "        \"CHROME\",\n",
    "        \"GRAINED\",\n",
    "        \"PAINTED\",\n",
    "        \"CARDAMOM\",\n",
    "        \"BLACK\",\n",
    "        \"WHITE\",\n",
    "        \"WOOD\",\n",
    "        \"LIGHT ASH\",\n",
    "        \"LIGHT GUI\",\n",
    "        \"METAL\",\n",
    "        \"LUMIERE\",\n",
    "        \"FOG MELANGE\",\n",
    "    ]\n",
    "    train = TYPE_process(data_base_processed,mylist)\n",
    "    mytest = TYPE_process(test_processed , mylist)\n",
    "    \"\"\"\n",
    "    train = TYPE_process(train,mylist)\n",
    "    mytest = TYPE_process(mytest , mylist)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_cos_sim = w2v_similarity(train,mytest)\n",
    "    \n",
    "    \n",
    "    #跑流程图, \n",
    "    each_test_candidates =mytest.apply(lambda x :find_best_candidates(x,train,new_in = []), axis=1)\n",
    "    \n",
    "    output = get_output(each_test_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b310edd-d800-461b-8728-9b5f000e456e",
   "metadata": {},
   "source": [
    "### 若从data_base中随意选取3000个，检测正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416bbad-ce28-4728-8da0-86eea9231897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_test\n",
    "output[\"single_volume\"] = output[\"LENGTH(MM)\"] * output[\"WIDTH(MM)\"] * output[\"HEIGHT(MM)\"] / output[\"UL\"]\n",
    "mytest[\"single_volume\"] = mytest[\"LENGTH(MM)\"] * mytest[\"WIDTH(MM)\"] * mytest[\"HEIGHT(MM)\"]/mytest[\"UL\"]\n",
    "output[\"true_volume\"] = [i for i in mytest[\"single_volume\"] for j in range(3)]\n",
    "\n",
    "output[\"diff\"] = abs(output[\"true_volume\"] - output[\"single_volume\"]) / output[\"true_volume\"]\n",
    "\n",
    "summary = output.groupby(\"level_0\").agg({\"diff\":\"min\"})\n",
    "\n",
    "sum(summary[\"diff\"] == 0)\n",
    "sum((summary[\"diff\"] > 0) & (summary[\"diff\"] < 0.3))\n",
    "sum((summary[\"diff\"] > 0) & (summary[\"diff\"] < 0.2))\n",
    "\n",
    "SUMMARY = output.loc[output[\"level_1\"] == 0]\n",
    "sum(SUMMARY[\"diff\"] == 0)\n",
    "sum((SUMMARY[\"diff\"] > 0) & (SUMMARY[\"diff\"] < 0.3))\n",
    "sum((SUMMARY[\"diff\"] > 0) & (SUMMARY[\"diff\"] < 0.2))\n",
    "\n",
    "mm_big = output.loc[output[\"true_volume\"] >= 1e6]\n",
    "\n",
    "summary_big = mm_big.groupby(\"level_0\").agg({\"diff\": \"min\"})\n",
    "sum(summary_big[\"diff\"] == 0)\n",
    "sum((summary_big[\"diff\"] > 0) & (summary[\"diff\"] < 0.3))\n",
    "sum((summary_big[\"diff\"] > 0) & (summary[\"diff\"] < 0.2))\n",
    "\n",
    "mm_big = output.loc[output[\"true_volume\"] >= 1e6]\n",
    "SUMMARY_big = mm_big.loc[mm_big[\"level_1\"] == 0]\n",
    "sum(SUMMARY_big[\"diff\"] == 0)\n",
    "sum((SUMMARY_big[\"diff\"] > 0) & (SUMMARY_big[\"diff\"] < 0.3))\n",
    "sum((SUMMARY_big[\"diff\"] > 0) & (SUMMARY_big[\"diff\"] < 0.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
